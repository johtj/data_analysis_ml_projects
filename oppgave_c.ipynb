{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30bbf5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9efcbf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(x, p,intercept=False):\n",
    "\n",
    "    \"\"\" \n",
    "    Generates a polynomial feature matrix with or without\n",
    "    intercept, based on the values of x. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy vector shape(n,p), if intercept shape(n,p+1)\n",
    "        the resulting feature matrix of all polynomial combinations\n",
    "        up to a given degree. Vandermonde format.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy vector shape(n)\n",
    "        x values from dataset\n",
    "\n",
    "    p : int\n",
    "        number of degrees \n",
    "\n",
    "    intercept : Bool\n",
    "        Bool to determine if intercept should be included or not:\n",
    "        False : no intercept \n",
    "        True : include intercept\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(x)\n",
    "\n",
    "    #handling the intercept column\n",
    "    #to avoid branching in loop\n",
    "    if intercept: \n",
    "        matrix_p = p+1\n",
    "        start_col = 1\n",
    "        i_offs = 0\n",
    "\n",
    "        X = np.zeros((n, matrix_p))\n",
    "        X[:,0] = np.ones(n)\n",
    "   \n",
    "    else:\n",
    "        matrix_p = p\n",
    "        start_col = 0\n",
    "        i_offs = 1\n",
    "    \n",
    "        X = np.zeros((n, matrix_p))\n",
    "    \n",
    "    for i in range(start_col,matrix_p):\n",
    "            X[:,i] = np.power(x,i+i_offs)\n",
    "     \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81b12e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_parameters(X, y):\n",
    "    \"\"\"\n",
    "        Calculates the optimal parameters, theta, using the \n",
    "        ordinary least squares method.  \n",
    "\n",
    "        Theta_OLS = inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        theta : numpy array shape (n)\n",
    "            the optimal parameters, theta as given by the\n",
    "            OLS method. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array shape (n,f)\n",
    "            Feature matrix for the data, where n is the number\n",
    "            of data points and f is the number of features.\n",
    "        \n",
    "        y : numpy array shape (n)\n",
    "            Y values of the data set.     \n",
    "    \"\"\"\n",
    "\n",
    "    #calculate X^T*X and take the inverse\n",
    "    XTX = X.T@X\n",
    "    XTX_i = np.linalg.inv(XTX)\n",
    "\n",
    "    #calculate X^T*y\n",
    "    XT_y = X.T @ y\n",
    "    \n",
    "    #calculate theta\n",
    "    theta = XTX_i @ XT_y\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b7fa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_parameters(X, y, lamb):\n",
    "    \"\"\"\n",
    "        Calculates the optimal parameters, r_params, using the \n",
    "        ridge regression method.  \n",
    "\n",
    "        r_params = inv(X.T @ X + lambda I) @ X.T @ y\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        r_params : numpy array shape (n)\n",
    "            the optimal parameters, theta as given by the\n",
    "            Ridge regression method. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array shape (n,f)\n",
    "            Feature matrix for the data, where n is the number\n",
    "            of data points and f is the number of features.\n",
    "        \n",
    "        y : numpy array shape (n)\n",
    "            Y values of the data set.     \n",
    "    \"\"\"\n",
    "        \n",
    "    # Assumes X is scaled and has no intercept column    \n",
    "    \n",
    "    p = X.shape[1]\n",
    "    I = np.eye(p)\n",
    "\n",
    "    r_params = np.linalg.inv(X.T @ X + lamb * I) @ X.T @ y\n",
    "\n",
    "    return r_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d06c8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_ridge(X,y,eta,lam,num_iters,n_features):\n",
    "    \"\"\"\n",
    "        Calculates the optimal parameters, theta, using the \n",
    "        ridge regression and gradient descent\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        theta_gdRidge : numpy array shape (n)\n",
    "            the optimal parameters, theta as given by the\n",
    "            OLS method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array shape (n,f)\n",
    "            Feature matrix for the data, where n is the number\n",
    "            of data points and f is the number of features.\n",
    "\n",
    "        y : numpy array shape (n)\n",
    "            Y values of the data set. \n",
    "        \n",
    "        eta : int\n",
    "            gradient descent parameter\n",
    "    \n",
    "        lam : int\n",
    "            learning rate\n",
    "        \n",
    "        num_iters : int\n",
    "            number of iterations\n",
    "\n",
    "        n_features : int\n",
    "            number of features in feature matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize weights for gradient descent\n",
    "    theta_gdRidge = np.zeros(n_features)\n",
    "\n",
    "    # Gradient descent loop\n",
    "    for t in range(num_iters):\n",
    "        # Compute gradients for Ridge\n",
    "        grad_Ridge = (2.0/n) * X.T @(X @ theta_gdRidge - y) + 2*lam*theta_gdRidge\n",
    "\n",
    "        # Update parameters theta\n",
    "        theta_gdRidge -= eta*grad_Ridge \n",
    "\n",
    "    # After the loop, theta contains the fitted coefficients\n",
    "    return theta_gdRidge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0e327f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_OLS(X,y,eta,num_iters,n_features):\n",
    "    \"\"\"\n",
    "        Calculates the optimal parameters, theta, using the \n",
    "        ordinary least squares method and gradient descent\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        theta_gdOLS : numpy array shape (n)\n",
    "            the optimal parameters, theta as given by the\n",
    "            OLS method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array shape (n,f)\n",
    "            Feature matrix for the data, where n is the number\n",
    "            of data points and f is the number of features.\n",
    "\n",
    "        y : numpy array shape (n)\n",
    "            Y values of the data set. \n",
    "        \n",
    "        eta : int\n",
    "            gradient descent parameter\n",
    "    \n",
    "        lam : int\n",
    "            learning rate\n",
    "        \n",
    "        num_iters : int\n",
    "            number of iterations\n",
    "\n",
    "        n_features : int\n",
    "            number of features in feature matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize weights for gradient descent\n",
    "    theta_gdOLS = np.zeros(n_features)\n",
    "\n",
    "    # Gradient descent loop\n",
    "    for t in range(num_iters):\n",
    "        # Compute gradients for OSL and Ridge\n",
    "        grad_OLS = (2.0/n)*X.T @ (X @ theta_gdOLS - y)\n",
    "\n",
    "        # Update parameters theta\n",
    "        theta_gdOLS -= eta*grad_OLS\n",
    "\n",
    "    # After the loop, theta contains the fitted coefficients\n",
    "    return theta_gdOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b755de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runge_function(x):\n",
    "    \"\"\"\n",
    "        The Runge function, f(x) = 1/(1+25*x^2)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        f : numpy array shape (n)\n",
    "            the Runge function evaluated at each point in x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy array shape (n)\n",
    "            x values from dataset\n",
    "    \"\"\"\n",
    "\n",
    "    f = 1/(1+25*x**2) \n",
    "\n",
    "    return f\n",
    "\n",
    "np.random.seed(0) # For reproducibility\n",
    "# Generate synthetic data\n",
    "n = 100\n",
    "x = np.linspace(-1, 1, n)\n",
    "y = runge_function(x) + 0.1 * np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33ca7aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for eta = 0.001:\n",
      "  Gradient Descent OLS Parameters: [ 0.24269139 -0.00626545 -0.02047827 -0.00326185 -0.01677792 -0.00296296]\n",
      "  Gradient Descent Ridge Parameters: [ 0.22646114 -0.00577556 -0.01647982 -0.00302035 -0.01396908 -0.00273419]\n",
      "  OLS Parameters: [ 0.62930554 -0.08291809 -2.14154267  0.29736638  1.8125738  -0.25555585]\n",
      "  Ridge Parameters: [ 0.58044407 -0.04131374 -1.71638535  0.11813179  1.34988738 -0.10256581]\n",
      "\n",
      "Results for eta = 0.01:\n",
      "  Gradient Descent OLS Parameters: [ 4.19761302e-01 -1.20847155e-02 -3.56043216e-01 -1.07008629e-04\n",
      " -1.09625616e-01 -5.23156150e-03]\n",
      "  Gradient Descent Ridge Parameters: [ 0.32039495 -0.00895849 -0.17201815 -0.00236766 -0.07671639 -0.00397566]\n",
      "  OLS Parameters: [ 0.62930554 -0.08291809 -2.14154267  0.29736638  1.8125738  -0.25555585]\n",
      "  Ridge Parameters: [ 0.58044407 -0.04131374 -1.71638535  0.11813179  1.34988738 -0.10256581]\n",
      "\n",
      "Results for eta = 0.1:\n",
      "  Gradient Descent OLS Parameters: [ 0.52387539 -0.02227376 -1.1972479   0.03530517  0.77449512 -0.03157816]\n",
      "  Gradient Descent Ridge Parameters: [ 0.3222622  -0.00910421 -0.18156953 -0.00204294 -0.06940829 -0.0041145 ]\n",
      "  OLS Parameters: [ 0.62930554 -0.08291809 -2.14154267  0.29736638  1.8125738  -0.25555585]\n",
      "  Ridge Parameters: [ 0.58044407 -0.04131374 -1.71638535  0.11813179  1.34988738 -0.10256581]\n",
      "\n",
      "Results for eta = 0.5:\n",
      "  Gradient Descent OLS Parameters: [ 0.62280963 -0.04755315 -2.08336147  0.14453626  1.74861426 -0.1249317 ]\n",
      "  Gradient Descent Ridge Parameters: [ 0.3222622  -0.00910421 -0.18156953 -0.00204294 -0.06940829 -0.0041145 ]\n",
      "  OLS Parameters: [ 0.62930554 -0.08291809 -2.14154267  0.29736638  1.8125738  -0.25555585]\n",
      "  Ridge Parameters: [ 0.58044407 -0.04131374 -1.71638535  0.11813179  1.34988738 -0.10256581]\n",
      "\n",
      "Results for eta = 1:\n",
      "  Gradient Descent OLS Parameters: [-2.50523372e+135 -7.26331379e+119 -9.70698386e+134 -2.38531022e+119\n",
      " -6.28563374e+134 -2.66500249e+119]\n",
      "  Gradient Descent Ridge Parameters: [-4.21411165e+194 -9.14287274e+178 -1.63283423e+194 -7.22378431e+178\n",
      " -1.05732101e+194 -5.68975948e+178]\n",
      "  OLS Parameters: [ 0.62930554 -0.08291809 -2.14154267  0.29736638  1.8125738  -0.25555585]\n",
      "  Ridge Parameters: [ 0.58044407 -0.04131374 -1.71638535  0.11813179  1.34988738 -0.10256581]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate polynomial features\n",
    "degree = 5 # Degree of the polynomial features\n",
    "X = polynomial_features(x,degree,intercept=True) # Generate polynomial features\n",
    "n_features = X.shape[1] # Number of features\n",
    "\n",
    "# Hyperparameters\n",
    "eta_list = [0.001, 0.01, 0.1, 0.5, 1] # Learning rates to test\n",
    "num_iters = 1000 # Number of iterations for gradient descent\n",
    "lamb = 0.1 # Regularization parameter for Ridge\n",
    "\n",
    "results = {} # Dictionary to store results\n",
    "\n",
    "# Perform gradient descent for each eta and compare with OLS and Ridge\n",
    "\n",
    "for eta in eta_list: # Loop over each learning rate\n",
    "    theta_gdOLS = gradient_descent_OLS(X, y, eta, num_iters, n_features)\n",
    "    theta_gdRidge = gradient_descent_ridge(X, y, eta, lamb, num_iters, n_features)\n",
    "    theta_OLS = OLS_parameters(X, y)\n",
    "    theta_Ridge = Ridge_parameters(X, y, lamb)\n",
    "\n",
    "    results[eta] = {\n",
    "        'theta_gdOLS': theta_gdOLS,\n",
    "        'theta_gdRidge': theta_gdRidge,\n",
    "        'theta_OLS': theta_OLS,\n",
    "        'theta_Ridge': theta_Ridge\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for eta, params in results.items():\n",
    "    print(f\"Results for eta = {eta}:\")\n",
    "    print(f\"  Gradient Descent OLS Parameters: {params['theta_gdOLS']}\")\n",
    "    print(f\"  Gradient Descent Ridge Parameters: {params['theta_gdRidge']}\")\n",
    "    print(f\"  OLS Parameters: {params['theta_OLS']}\")\n",
    "    print(f\"  Ridge Parameters: {params['theta_Ridge']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51180e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def mse(X, y, theta):\n",
    "    return np.mean((X @ theta - y) ** 2)\n",
    "\n",
    "etas = [0.001, 0.01, 0.1, 0.5, 1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for eta in etas:\n",
    "    theta = np.zeros(n_features)\n",
    "    mse_history = []\n",
    "    for t in range (num_iters):\n",
    "        grad = (2.0/len(y)) * X.T @(X @ theta - y)\n",
    "        theta -= eta*grad\n",
    "        mse_history.append(mse(X, y, theta))\n",
    "        \n",
    "        \n",
    "plt.plot(range(num_iters), mse_history, label=f'eta={eta}')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE over Iterations for Gradient Descent OLS')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13168e5a",
   "metadata": {},
   "source": [
    "In this part we replaced the expressions for the optimal parameters $\\theta$ from $OLS$ and Ridge with our own gradient decent code. With moderate $\\eta$ from 0.01 to 0.1 we got a MSE that matched well with the closed-form. A low $\\eta$ of 0.001 gave us a very slow convergence, while a high $\\eta$ gave a spike in the graph for values from 0.5 to 1. So this shows us that the gradient decent works, but the $\\eta$ is critical, where its important to choose the \"sweet spot\" to avoid slow convergence or unstability. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
