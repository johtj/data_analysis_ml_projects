{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from matrix_creation import polynomial_features, standard_scaler,scale_features_by_intercept_use\n",
    "from main_methods import OLS_parameters,Ridge_parameters,gradient_descent_OLS,gradient_descent_ridge\n",
    "from errors import MSE,R2\n",
    "from plotting_exploration import plot_mse,plot_r2,explore_lambda,explore_polynomial_degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runge's function\n",
    "\n",
    "# parameters to explore\n",
    "n_datapoints = 100 # changed and ran code with different values. Could have been implemented as a list and looped over, but regarded as not necessary.\n",
    "standard_deviation = 0.1 # for noise, should we play around with this values as well in analysis?\n",
    "p = 15 # polynomial degree\n",
    "\n",
    "lambda_range = (-1,-5) # range of lambda values for np.log\n",
    "lambda_n = 50 # number lambda values to explore\n",
    "\n",
    "np.random.seed(250)  # ensure reproducibility\n",
    "\n",
    "# generating data without noise\n",
    "x = np.linspace(-1, 1, num=n_datapoints)\n",
    "y = 1 / (1 + 25 * x**2)\n",
    "\n",
    "# generating data with noise\n",
    "x_noise = np.linspace(-1, 1, num=n_datapoints) + np.random.normal(0, standard_deviation, n_datapoints)\n",
    "y_noise = 1 / (1 + 25 * x_noise**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089cc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runge's function analysis\n",
    "##################################################\n",
    "\n",
    "use_intercept = True # changed to variable to easily switch between True and False\n",
    "\n",
    "# No noise\n",
    "# creating design matrix with polynomial features: p\n",
    "X = polynomial_features(x, p,intercept=use_intercept) # intercept=True gives intercept column = 0 in standard scaler if intercept is True, and hence division by 0. \n",
    "\n",
    "# test and train dataset, and scaling of X_train and X_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train_scaled, X_test_scaled = scale_features_by_intercept_use(X_train, X_test, use_intercept)\n",
    "\n",
    "# scaled data for features as input \n",
    "polynomial_degree, mse_train, mse_test, r2_train, r2_test = explore_polynomial_degree(X_train_scaled, X_test_scaled, y_train, y_test, p, use_intercept=use_intercept)\n",
    "plot_mse(n_datapoints, polynomial_degree,\"Polynomial degrees\", mse_train, mse_test, noise=False)\n",
    "plot_r2(n_datapoints, polynomial_degree,\"Polynomial degrees\", r2_train, r2_test, noise=False)\n",
    "\n",
    "lambdas, mse_train_ridge, mse_test_ridge, r2_train_ridge, r2_test_ridge = explore_lambda(X_train_scaled, X_test_scaled, y_train, y_test,lambda_range,lambda_n)\n",
    "plot_mse(n_datapoints, lambdas,\"Lambda values\", mse_train_ridge, mse_test_ridge, noise=False)\n",
    "plot_r2(n_datapoints, lambdas,\"Lambda values\", r2_train_ridge, r2_test_ridge, noise=False)\n",
    "\n",
    "\n",
    "##################################################\n",
    "\n",
    "# With noise\n",
    "# creating design matrix with polynomial features: p\n",
    "X_noise = polynomial_features(x_noise, p,intercept=use_intercept) # intercept=True gives intercept column = 0 in standard scaler if intercept is True, and hence division by 0. Leaving intercept out since Ridge regression handles this\n",
    "\n",
    "# test and train dataset, and scaling of X_train and X_test\n",
    "X_train_noise, X_test_noise, y_train_noise, y_test_noise = train_test_split(X_noise, y_noise, test_size=0.2)\n",
    "X_train_scaled_noise, X_test_scaled_noise = scale_features_by_intercept_use(X_train_noise, X_test_noise, use_intercept)\n",
    "\n",
    "# scaled data for features as input \n",
    "polynomial_degree, mse_train, mse_test, r2_train, r2_test = explore_polynomial_degree(X_train_scaled_noise, X_test_scaled_noise, y_train_noise, y_test_noise, p, use_intercept=use_intercept)\n",
    "plot_mse(n_datapoints, polynomial_degree, \"polynomial degrees\", mse_train, mse_test, noise=True)\n",
    "plot_r2(n_datapoints, polynomial_degree, \"polynomial degrees\",r2_train, r2_test, noise=True)\n",
    "\n",
    "lambdas, mse_train_ridge, mse_test_ridge, r2_train_ridge, r2_test_ridge = explore_lambda(X_train_scaled_noise, X_test_scaled_noise, y_train_noise, y_test_noise,lambda_range,lambda_n)\n",
    "plot_mse(n_datapoints, lambdas,\"Lambda values\", mse_train_ridge, mse_test_ridge, noise=False)\n",
    "plot_r2(n_datapoints, lambdas,\"Lambda values\", r2_train_ridge, r2_test_ridge, noise=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
