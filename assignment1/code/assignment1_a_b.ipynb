{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4829e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import common modules\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import own modules\n",
    "from source.matrix_creation import polynomial_features,scale_features_by_intercept_use,standard_scaler\n",
    "from source.main_methods import rescale_theta_intercept, predict_y, rescale_y\n",
    "from source.plotting_exploration import plot_mse,plot_r2,explore_lambda,explore_polynomial_degree,plot_xy_xynoise_ypredicted,plot_theta_by_polynomials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b7da29",
   "metadata": {},
   "source": [
    "## Notebook for assignment 1 parts a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2782ecf4",
   "metadata": {},
   "source": [
    "Generating analysis plots for assignemtn 1 parts a) and b) exploring ordinary least squares and ridge regression. \n",
    "\n",
    "* Functions for the main methods can be found in source/main_methods.py\n",
    "* Functions generating and scaling the feature matrix can be found in source/matrix_creation.py \n",
    "* Functions for calculating errors can be found in source/errors.py\n",
    "* Functions for plotting and exploration can be found in source/plotting_exploration.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e2281",
   "metadata": {},
   "source": [
    "### Setup for constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runge's function - parameters to explore\n",
    "n_datapoints = 200\n",
    "standard_deviation = 0.1 # for noise\n",
    "p = 15 # polynomial degree\n",
    "\n",
    "lambda_range = (-1,-5) # range of lambda values for np.log\n",
    "lambda_n = 20 # number lambda values to explore\n",
    "lambdas_start = np.logspace(lambda_range[0],lambda_range[1],lambda_n) # lambdas generated in logspace for learning rate\n",
    "\n",
    "# Grid search\n",
    "etas = [0.001, 0.005, 0.01, 0.05, 0.1] # gradient descent parameters\n",
    "\n",
    "# tolerance criteria for gradient descent methods\n",
    "tolerance = 1e-6\n",
    "max_iterations = 1000\n",
    "\n",
    "use_intercept = True \n",
    "create_plots = False\n",
    "verbose_bool = False\n",
    "\n",
    "np.random.seed(250)  # ensure reproducibility numpy\n",
    "random_state_int = 42   # ensure reproducibility train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03adf687",
   "metadata": {},
   "source": [
    "### Generate Runge's function data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1219fe8",
   "metadata": {},
   "source": [
    "#### No noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating data without noise\n",
    "x = np.linspace(-1, 1, num=n_datapoints)\n",
    "y = 1 / (1 + 25 * x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6727d84",
   "metadata": {},
   "source": [
    "#### With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating data with noise\n",
    "x_noise = x\n",
    "y_noise = 1 / (1 + 25 * x_noise**2) + np.random.normal(0, standard_deviation, n_datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499fff93",
   "metadata": {},
   "source": [
    "### Generate feature matrix, scale and split into training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19599db",
   "metadata": {},
   "source": [
    "#### No noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0655f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating design matrix with polynomial features: p\n",
    "X = polynomial_features(x, p,intercept=use_intercept) # intercept=True gives intercept column = 0 in standard scaler if intercept is True, and hence division by 0. \n",
    "\n",
    "# split x for plotting\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=random_state_int)\n",
    "# test and train dataset, and scaling of X_train and X_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state_int)\n",
    "X_train_scaled, X_test_scaled, X_train_mean, X_train_std = scale_features_by_intercept_use(X_train, X_test, use_intercept)\n",
    "# scaling of y_train and y_test\n",
    "y_train_scaled, y_test_scaled, y_train_mean, y_train_std = standard_scaler(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6d91d",
   "metadata": {},
   "source": [
    "#### With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f21fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating design matrix with polynomial features: p\n",
    "X_noise = polynomial_features(x_noise, p,intercept=use_intercept) # intercept=True gives intercept column = 0 in standard scaler if intercept is True, and hence division by 0. Leaving intercept out since Ridge regression handles this\n",
    "\n",
    "# test and train dataset, and scaling of X_train and X_test\n",
    "x_train_noise, x_test_noise, y_train_noise, y_test_noise = train_test_split(x_noise, y_noise, test_size=0.2, random_state=random_state_int)\n",
    "X_train_noise, X_test_noise, y_train_noise, y_test_noise = train_test_split(X_noise, y_noise, test_size=0.2, random_state = random_state_int)\n",
    "X_train_scaled_noise, X_test_scaled_noise, X_mean, X_std = scale_features_by_intercept_use(X_train_noise, X_test_noise, use_intercept)\n",
    "# scaling of y_train and y_test\n",
    "y_train_scaled_noise, y_test_scaled_noise, y_train_mean_noise, y_train_std_noise = standard_scaler(y_train_noise, y_test_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f31836",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb6f578",
   "metadata": {},
   "source": [
    "#### Explore OLS in regards to polynomial degree, without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b03fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte OLS with sklearn as baseline values of intercept and theta\n",
    "# Compare other regression results to this\n",
    "ols_model_not_scaled = LinearRegression(fit_intercept=use_intercept)\n",
    "ols_model_scaled = LinearRegression(fit_intercept=use_intercept)\n",
    "ols_sklearn_not_scaled = ols_model_not_scaled.fit(X_train, y_train)\n",
    "ols_sklearn_scaled = ols_model_scaled.fit(X_train_scaled, y_train_scaled)\n",
    "print(\"Baseline with OLS for comparison of other regressions\")\n",
    "print(f\"sklearn OLS not scaled. Coef: {ols_sklearn_not_scaled.coef_}, intercept: {ols_sklearn_not_scaled.intercept_} \")\n",
    "print(f\"sklearn OLS scaled. Coef: {ols_sklearn_scaled.coef_}, intercept: {ols_sklearn_scaled.intercept_}\")\n",
    "print('\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled data for features as input \n",
    "polynomial_degree, mse_train, mse_test, r2_train, r2_test, thetas_ols_noise = explore_polynomial_degree(X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, p, use_intercept=use_intercept, verbose=verbose_bool)\n",
    "\n",
    "# rescaled coef and intercept as qc\n",
    "rescaled_coef_ols, rescaled_intercept_ols = rescale_theta_intercept(thetas_ols_noise[-1][1:], thetas_ols_noise[-1][0], y_train_std, y_train_mean, X_train_std, X_train_mean, verbose=verbose_bool)\n",
    "y_predicted_scaled_ols = predict_y(X_test_scaled[:, 1:], rescaled_coef_ols)\n",
    "y_predicted_rescaled_ols = rescale_y(y_predicted_scaled_ols, y_train_std, y_train_mean)\n",
    "if create_plots:\n",
    "    plot_mse(\"OLS\", p, n_datapoints, polynomial_degree, mse_train, mse_test, noise=False)\n",
    "    plot_r2(\"OLS\", p, n_datapoints, polynomial_degree, r2_train, r2_test, noise=False)\n",
    "    plot_mse(\"OLS\", p, n_datapoints, polynomial_degree, mse_train, mse_test, noise=False)\n",
    "    plot_r2(\"OLS\", p, n_datapoints, polynomial_degree, r2_train, r2_test, noise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e59f40",
   "metadata": {},
   "source": [
    "#### Explore OLS in regards to polynomial degree, with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled data for features as input\n",
    "polynomial_degree, mse_train, mse_test, r2_train, r2_test, thetas_ols_noise = explore_polynomial_degree(X_train_scaled_noise, X_test_scaled_noise, y_train_scaled_noise, y_test_scaled_noise, p, use_intercept=use_intercept, verbose=verbose_bool)\n",
    "# rescaled coef and intercept as qc, calculated rescaled y_predict\n",
    "rescaled_coef_ols_noise, rescaled_intercept_ols_noise = rescale_theta_intercept(thetas_ols_noise[-1][1:], thetas_ols_noise[-1][0], y_train_std, y_train_mean, X_train_std, X_train_mean, verbose=verbose_bool)\n",
    "y_predicted_scaled_ols_noise = predict_y(X_test_scaled_noise[:, 1:], rescaled_coef_ols_noise)\n",
    "y_predicted_rescaled_ols_noise = rescale_y(y_predicted_scaled_ols_noise, y_train_std, y_train_mean)\n",
    "\n",
    "if create_plots: #MSE, R2 and function with noise\n",
    "    plot_xy_xynoise_ypredicted(x, y, x_train_noise, y_train_noise, y_predicted_rescaled_ols_noise, x_test, n_datapoints, \"OLS\", p, True, lambda_n, 0, etas, max_iterations)\n",
    "    plot_mse(\"OLS\", p, n_datapoints, polynomial_degree, mse_train, mse_test, noise=True)\n",
    "    plot_r2(\"OLS\", p, n_datapoints, polynomial_degree, r2_train, r2_test, noise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b179e6",
   "metadata": {},
   "source": [
    "#### Explore Ridge regression in regards to lambda values, without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore lambdas with Ridge regression - no noise\n",
    "mse_train_ridge, mse_test_ridge, r2_train_ridge, r2_test_ridge, theta_ridge = explore_lambda(X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, lambdas_start, verbose=verbose_bool)\n",
    "# rescaled coef and intercept as qc\n",
    "rescaled_coef_ridge, rescaled_intercept_ridge = rescale_theta_intercept(theta_ridge[-1][1:], theta_ridge[-1][0], y_train_std, y_train_mean, X_train_std, X_train_mean, verbose=verbose_bool)\n",
    "y_predicted_scaled_ridge = predict_y(X_test_scaled[:, 1:], rescaled_coef_ridge)\n",
    "y_predicted_rescaled_ridge = rescale_y(y_predicted_scaled_ridge, y_train_std, y_train_mean)\n",
    "\n",
    "if create_plots: #MSE and R2 with no noise\n",
    "    plot_mse(\"Ridge\", p, n_datapoints, lambdas_start, mse_train_ridge, mse_test_ridge, noise=False)\n",
    "    plot_r2(\"Ridge\", p, n_datapoints, lambdas_start, r2_train_ridge, r2_test_ridge, noise=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e73b9bb",
   "metadata": {},
   "source": [
    "#### Explore Ridge regression in regards to lambda values, with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ba1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot theta values as function if polynomial degree\n",
    "if create_plots: plot_theta_by_polynomials(thetas_ols_noise, p, n_datapoints)\n",
    "\n",
    "# Explore lambdas with Ridge regression - noise\n",
    "mse_train_ridge, mse_test_ridge, r2_train_ridge, r2_test_ridge, thetas_ridge_noise = explore_lambda(X_train_scaled_noise, X_test_scaled_noise, y_train_scaled_noise, y_test_scaled_noise, lambdas_start, verbose=verbose_bool)\n",
    "\n",
    "if create_plots:\n",
    "    # for plotting ridge dependent on different lambda values, rescaled coef and intercept also as qc\n",
    "    for i, theta in enumerate(theta_ridge):\n",
    "        rescaled_coef_ridge_noise, rescaled_intercept_ridge_noise = rescale_theta_intercept(theta[1:], theta[0], y_train_std, y_train_mean, X_train_std, X_train_mean, verbose=verbose_bool)\n",
    "        y_predicted_scaled_ridge_noise = predict_y(X_test_scaled[:, 1:], rescaled_coef_ridge_noise)\n",
    "        y_predicted_rescaled_ridge_noise = rescale_y(y_predicted_scaled_ridge_noise, y_train_std, y_train_mean)\n",
    "        plot_xy_xynoise_ypredicted(x, y, x_train_noise, y_train_noise, y_predicted_rescaled_ridge_noise, x_test, n_datapoints, \"Ridge\", p, False, lambda_n, lambdas_start[i], 0, max_iterations)\n",
    "\n",
    "if create_plots:\n",
    "    plot_mse(\"Ridge\", p, n_datapoints, lambdas_start, mse_train_ridge, mse_test_ridge, noise=True)\n",
    "    plot_r2(\"Ridge\", p, n_datapoints, lambdas_start, r2_train_ridge, r2_test_ridge, noise=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2_electric_boogalo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
