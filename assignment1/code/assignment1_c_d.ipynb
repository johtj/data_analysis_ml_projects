{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import common modules\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import own modules\n",
    "from source.matrix_creation import polynomial_features,scale_features_by_intercept_use\n",
    "from source.plotting_exploration import explore_eta,explore_n\n",
    "from source.plotting_exploration import plot_mse,plot_r2\n",
    "from source.plotting_exploration import explore_iterations_GD_methods_ridge,explore_iterations_GD_methods_OLS\n",
    "from source.plotting_exploration import explore_n_epochs_stochasticGD_ridge,explore_n_epochs_stochasticGD_OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d612b8b",
   "metadata": {},
   "source": [
    "## Notebook for assignment 1 parts c,d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c478f",
   "metadata": {},
   "source": [
    "Generating analysis plots for assignement 1 parts c) and d) exploring Gradient descent for various methods for updating the learning rate. \n",
    "\n",
    "* Functions for the main methods can be found in source/GD_OLS.py and source/GD_Ridge.py\n",
    "* Functions generating and scaling the feature matrix can be found in source/matrix_creation.py \n",
    "* Functions for calculating errors can be found in source/errors.py\n",
    "* Functions for plotting and exploration can be found in source/plotting_exploration.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ab792",
   "metadata": {},
   "source": [
    "### Setup for constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687ee8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runge's function - parameters to explore\n",
    "n_datapoints = 200\n",
    "standard_deviation = 0.1 # for noise\n",
    "p = 15 # polynomial degree\n",
    "\n",
    "lambda_range = (-1,-5) # range of lambda values for np.log\n",
    "lambda_n = 20 # number lambda values to explore\n",
    "lambdas_start = np.logspace(lambda_range[0],lambda_range[1],lambda_n) # lambdas generated in logspace for learning rate\n",
    "\n",
    "# Grid search\n",
    "etas = [0.001, 0.005, 0.01, 0.05, 0.1] # gradient descent parameters\n",
    "\n",
    "# tolerance criteria for gradient descent methods\n",
    "tolerance = 1e-6\n",
    "max_iterations = 1000\n",
    "\n",
    "use_intercept = True \n",
    "create_plots = False\n",
    "verbose_bool = False\n",
    "\n",
    "np.random.seed(250)  # ensure reproducibility numpy\n",
    "random_state_int = 42   # ensure reproducibility train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb39f700",
   "metadata": {},
   "source": [
    "#### Constants for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_list = [0.00001,0.0001,0.001, 0.01, 0.1,0.12,0.121] \n",
    "num_iters = 1000\n",
    "\n",
    "iter_list = [10,50,100,1000,10000,100000]\n",
    "eta = 0.001\n",
    "lam = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4e373",
   "metadata": {},
   "source": [
    "### Generate Runge's function data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0335ec",
   "metadata": {},
   "source": [
    "#### No noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating data without noise\n",
    "x = np.linspace(-1, 1, num=n_datapoints)\n",
    "y = 1 / (1 + 25 * x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52c649",
   "metadata": {},
   "source": [
    "#### With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating data with noise\n",
    "x_noise = x\n",
    "y_noise = 1 / (1 + 25 * x_noise**2) + np.random.normal(0, standard_deviation, n_datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54e2afd",
   "metadata": {},
   "source": [
    "### Generate feature matrix, scale and split into training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a145ae",
   "metadata": {},
   "source": [
    "#### No noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d416dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating design matrix with polynomial features: p\n",
    "X = polynomial_features(x, p,intercept=use_intercept) # intercept=True gives intercept column = 0 in standard scaler if intercept is True, and hence division by 0. \n",
    "\n",
    "# split x for plotting\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=random_state_int)\n",
    "# test and train dataset, and scaling of X_train and X_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state_int)\n",
    "X_train_scaled, X_test_scaled, X_train_mean, X_train_std = scale_features_by_intercept_use(X_train, X_test, use_intercept)\n",
    "# scaling of y_train and y_test\n",
    "y_train_scaled, y_test_scaled, y_train_mean, y_train_std = standard_scaler(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e34fbf",
   "metadata": {},
   "source": [
    "#### With noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce9b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating design matrix with polynomial features: p\n",
    "X_noise = polynomial_features(x_noise, p,intercept=use_intercept) # intercept=True gives intercept column = 0 in standard scaler if intercept is True, and hence division by 0. Leaving intercept out since Ridge regression handles this\n",
    "\n",
    "# test and train dataset, and scaling of X_train and X_test\n",
    "x_train_noise, x_test_noise, y_train_noise, y_test_noise = train_test_split(x_noise, y_noise, test_size=0.2, random_state=random_state_int)\n",
    "X_train_noise, X_test_noise, y_train_noise, y_test_noise = train_test_split(X_noise, y_noise, test_size=0.2, random_state = random_state_int)\n",
    "X_train_scaled_noise, X_test_scaled_noise, X_mean, X_std = scale_features_by_intercept_use(X_train_noise, X_test_noise, use_intercept)\n",
    "# scaling of y_train and y_test\n",
    "y_train_scaled_noise, y_test_scaled_noise, y_train_mean_noise, y_train_std_noise = standard_scaler(y_train_noise, y_test_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ce3d5",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa689b1",
   "metadata": {},
   "source": [
    "#### Explore Gradient descent using OLS & Ridge for various eta, with no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_list,mse_train_OLS,mse_test_OLS,mse_train_Ridge,mse_test_Ridge,r2_train_gdOLS,r2_test_Ridge = explore_eta(X_train,X_test,y_train,y_test,num_iters,eta_list,lam,verbose=False)\n",
    "plot_mse(n_datapoints,etas,\"Gradient descent for Oridnary least squares varying Etas,\\n and 1000 iterations\",mse_train_OLS,mse_test_OLS)\n",
    "plot_mse(n_datapoints,etas,\"Gradient descent for Ridge regression varying Etas,\\n and 1000 iterations\",mse_train_Ridge,mse_test_Ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb92a5",
   "metadata": {},
   "source": [
    "#### Explore Gradient descent using OLS & Ridge for various eta, with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58192aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_list,mse_train_OLS,mse_test_OLS,mse_train_Ridge,mse_test_Ridge,r2_train_gdOLS,r2_test_Ridge = explore_eta(X_train,X_test,y_train,y_test,num_iters,eta_list,lam,verbose=False)\n",
    "plot_mse(n_datapoints,etas,\"Gradient descent for Oridnary least squares varying Etas,\\n and 1000 iterations\",mse_train_OLS,mse_test_OLS)\n",
    "plot_mse(n_datapoints,etas,\"Gradient descent for Ridge regression varying Etas,\\n and 1000 iterations\",mse_train_Ridge,mse_test_Ridge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28364f0a",
   "metadata": {},
   "source": [
    "#### Explore Gradient descent using OLS & Ridge for various number of iterations, with no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fbfc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_list,mse_train_OLS,mse_test_OLS,mse_train_Ridge,mse_test_Ridge,r2_train_gdOLS,r2_test_Ridge = explore_n(X_train,X_test,y_train,y_test,iter_list,lam,eta,verbose=False)\n",
    "\n",
    "plot_mse(n_datapoints,iter_list,\"Gradient descent for Oridnary least squares varying iterations,\\n and eta 0.15\",mse_train_OLS,mse_test_OLS)\n",
    "plot_mse(n_datapoints,iter_list,\"Gradient descent for Ridge regression varying varying iterations,\\n and eta 0.15\",mse_train_Ridge,mse_test_Ridge)\n",
    "print(mse_test_Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e2c1b7",
   "metadata": {},
   "source": [
    "#### Explore Gradient descent using OLS & Ridge for various number of iterations, with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdecb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_list,mse_train_OLS,mse_test_OLS,mse_train_Ridge,mse_test_Ridge,r2_train_gdOLS,r2_test_Ridge = explore_n(X_train,X_test,y_train,y_test,iter_list,lam,eta,verbose=False)\n",
    "\n",
    "plot_mse(n_datapoints,iter_list,\"Gradient descent for Oridnary least squares varying iterations,\\n and eta 0.15\",mse_train_OLS,mse_test_OLS)\n",
    "plot_mse(n_datapoints,iter_list,\"Gradient descent for Ridge regression varying varying iterations,\\n and eta 0.15\",mse_train_Ridge,mse_test_Ridge)\n",
    "print(mse_test_Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822c050",
   "metadata": {},
   "source": [
    "#### Explore Gradient descent using OLS, with different ways of updating the learning rate, for various number of iterations, with no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_iterations_GD_methods_OLS(iter_list,eta,\n",
    "                                  x,y,\n",
    "                                  x_train,x_test,\n",
    "                                  X_train_scaled,X_test_scaled,\n",
    "                                  y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb8550",
   "metadata": {},
   "source": [
    "#### Explore Gradient descent using OLS, with different ways of updating the learning rate, for various number of iterations, with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7089a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_iterations_GD_methods_OLS(iter_list,eta,\n",
    "                                  x,y,\n",
    "                                  x_train,x_test,\n",
    "                                  X_train_scaled,X_test_scaled,\n",
    "                                  y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b0e6bd",
   "metadata": {},
   "source": [
    "#### Explore Gradient descent using ridge regression, with different ways of updating the learning rate, for various number of iterations, with no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_iterations_GD_methods_ridge(iter_list,eta,lam,\n",
    "                                    x,y,\n",
    "                                    x_train,x_test,\n",
    "                                    X_train_scaled,X_test_scaled,\n",
    "                                    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed02a6e",
   "metadata": {},
   "source": [
    "#### Explore Gradient descent using ridge regression, with different ways of updating the learning rate, for various number of iterations, with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ace115",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_iterations_GD_methods_ridge(iter_list,eta,lam,\n",
    "                                    x,y,\n",
    "                                    x_train,x_test,\n",
    "                                    X_train_scaled,X_test_scaled,\n",
    "                                    y_train)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
