{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bbf5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efcbf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(x, p,intercept=False):\n",
    "\n",
    "    \"\"\" \n",
    "    Generates a polynomial feature matrix with or without\n",
    "    intercept, based on the values of x. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy vector shape(n,p), if intercept shape(n,p+1)\n",
    "        the resulting feature matrix of all polynomial combinations\n",
    "        up to a given degree. Vandermonde format.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy vector shape(n)\n",
    "        x values from dataset\n",
    "\n",
    "    p : int\n",
    "        number of degrees \n",
    "\n",
    "    intercept : Bool\n",
    "        Bool to determine if intercept should be included or not:\n",
    "        False : no intercept \n",
    "        True : include intercept\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(x)\n",
    "\n",
    "    #handling the intercept column\n",
    "    #to avoid branching in loop\n",
    "    if intercept: \n",
    "        matrix_p = p+1\n",
    "        start_col = 1\n",
    "        i_offs = 0\n",
    "\n",
    "        X = np.zeros((n, matrix_p))\n",
    "        X[:,0] = np.ones(n)\n",
    "   \n",
    "    else:\n",
    "        matrix_p = p\n",
    "        start_col = 0\n",
    "        i_offs = 1\n",
    "    \n",
    "        X = np.zeros((n, matrix_p))\n",
    "    \n",
    "    for i in range(start_col,matrix_p):\n",
    "            X[:,i] = np.power(x,i+i_offs)\n",
    "     \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b12e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_parameters(X, y):\n",
    "    \"\"\"\n",
    "        Calculates the optimal parameters, theta, using the \n",
    "        ordinary least squares method.  \n",
    "\n",
    "        Theta_OLS = inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        theta : numpy array shape (n)\n",
    "            the optimal parameters, theta as given by the\n",
    "            OLS method. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array shape (n,f)\n",
    "            Feature matrix for the data, where n is the number\n",
    "            of data points and f is the number of features.\n",
    "        \n",
    "        y : numpy array shape (n)\n",
    "            Y values of the data set.     \n",
    "    \"\"\"\n",
    "\n",
    "    #calculate X^T*X and take the inverse\n",
    "    XTX = X.T@X\n",
    "    XTX_i = np.linalg.inv(XTX)\n",
    "\n",
    "    #calculate X^T*y\n",
    "    XT_y = X.T @ y\n",
    "    \n",
    "    #calculate theta\n",
    "    theta = XTX_i @ XT_y\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7fa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_parameters(X, y, lamb):\n",
    "    \"\"\"\n",
    "        Calculates the optimal parameters, r_params, using the \n",
    "        ridge regression method.  \n",
    "\n",
    "        r_params = inv(X.T @ X + lambda I) @ X.T @ y\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        r_params : numpy array shape (n)\n",
    "            the optimal parameters, theta as given by the\n",
    "            Ridge regression method. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array shape (n,f)\n",
    "            Feature matrix for the data, where n is the number\n",
    "            of data points and f is the number of features.\n",
    "        \n",
    "        y : numpy array shape (n)\n",
    "            Y values of the data set.     \n",
    "    \"\"\"\n",
    "        \n",
    "    # Assumes X is scaled and has no intercept column    \n",
    "    \n",
    "    p = X.shape[1]\n",
    "    I = np.eye(p)\n",
    "\n",
    "    r_params = np.linalg.inv(X.T @ X + lamb * I) @ X.T @ y\n",
    "\n",
    "    return r_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_ridge(X,y,eta,lam,num_iters,n_features):\n",
    "    \"\"\"\n",
    "        Calculates the optimal parameters, theta, using the \n",
    "        ridge regression and gradient descent\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        theta_gdRidge : numpy array shape (n)\n",
    "            the optimal parameters, theta as given by the\n",
    "            OLS method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array shape (n,f)\n",
    "            Feature matrix for the data, where n is the number\n",
    "            of data points and f is the number of features.\n",
    "\n",
    "        y : numpy array shape (n)\n",
    "            Y values of the data set. \n",
    "        \n",
    "        eta : int\n",
    "            gradient descent parameter\n",
    "    \n",
    "        lam : int\n",
    "            learning rate\n",
    "        \n",
    "        num_iters : int\n",
    "            number of iterations\n",
    "\n",
    "        n_features : int\n",
    "            number of features in feature matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize weights for gradient descent\n",
    "    theta_gdRidge = np.zeros(n_features)\n",
    "\n",
    "    # Gradient descent loop\n",
    "    for t in range(num_iters):\n",
    "        # Compute gradients for Ridge\n",
    "        grad_Ridge = (2.0/n) * X.T @(X @ theta_gdRidge - y) + 2*lam*theta_gdRidge\n",
    "\n",
    "        # Update parameters theta\n",
    "        theta_gdRidge -= eta*grad_Ridge \n",
    "\n",
    "    # After the loop, theta contains the fitted coefficients\n",
    "    return theta_gdRidge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e327f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_OLS(X,y,eta,num_iters,n_features):\n",
    "    \"\"\"\n",
    "        Calculates the optimal parameters, theta, using the \n",
    "        ordinary least squares method and gradient descent\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        theta_gdOLS : numpy array shape (n)\n",
    "            the optimal parameters, theta as given by the\n",
    "            OLS method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array shape (n,f)\n",
    "            Feature matrix for the data, where n is the number\n",
    "            of data points and f is the number of features.\n",
    "\n",
    "        y : numpy array shape (n)\n",
    "            Y values of the data set. \n",
    "        \n",
    "        eta : int\n",
    "            gradient descent parameter\n",
    "    \n",
    "        lam : int\n",
    "            learning rate\n",
    "        \n",
    "        num_iters : int\n",
    "            number of iterations\n",
    "\n",
    "        n_features : int\n",
    "            number of features in feature matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize weights for gradient descent\n",
    "    theta_gdOLS = np.zeros(n_features)\n",
    "\n",
    "    # Gradient descent loop\n",
    "    for t in range(num_iters):\n",
    "        # Compute gradients for OSL and Ridge\n",
    "        grad_OLS = (2.0/n)*X.T @ (X @ theta_gdOLS - y)\n",
    "\n",
    "        # Update parameters theta\n",
    "        theta_gdOLS -= eta*grad_OLS\n",
    "\n",
    "    # After the loop, theta contains the fitted coefficients\n",
    "    return theta_gdOLS"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
